# pip install opencv-python-headless numpy
import cv2
import numpy as np

# Load the image
image = cv2.imread('./38549278-set-of-grey-vinyl-samples-texture-background.jpg')

# Convert the image to grayscale
gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

# Convert the grayscale image to a NumPy array
gray_array = np.array(gray_image)

# Display the shape of the NumPy array
print(gray_array.shape)

# Optionally, save the grayscale image
cv2.imwrite('grayscale_image.jpg', gray_image)

max(gray_array[0])
# import cv2
# import numpy as np

# # Ask the user for the image file path
# image_path = input("Enter the path to the image file: ")

# try:
#     # Load the image
#     image = cv2.imread(image_path)

#     # Convert the image to grayscale
#     gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

#     # Convert the grayscale image to a NumPy array
#     gray_array = np.array(gray_image)

#     # Display the shape of the NumPy array
#     print("Shape of the grayscale array:", gray_array.shape)

#     # Optionally, save the grayscale image
#     cv2.imwrite('grayscale_image.jpg', gray_image)

# except Exception as e:
#     print("An error occurred:", e)

# import random

# def generate_random_pixels(width, height, pixel_range):
#     pixels = [[(random.randint(pixel_range[0], pixel_range[1]))
#                for _ in range(width)]
#               for _ in range(height)]
#     return pixels

# # Define parameters
# width = 800
# height = 600
# pixel_range = (0, 49)  # Example: for grayscale L=50

# Generate 2D array of pixels
array1 = gray_array
array = np.array(array1, dtype=np.int16)


shape = gray_array.shape
width = shape[1]
height = shape[0]
pixel_range = (0, 255)
m=10 #horizontal j
n=10 #vertical i
d1 = 1 # horizontal
d2 = 0 # vertical
arr1 = {i: 0 for i in range(2*pixel_range[1]+1)}
arr2 = {i: 0 for i in range(-pixel_range[1], pixel_range[1]+1)}
temp_sum = {i: 0 for i in range(2*pixel_range[1]+1)}
temp_diff = {i: 0 for i in range(-pixel_range[1], pixel_range[1]+1)}
import numpy as np
import math

def ASM(S,D):
    Psum=0
    Pdiff=0

    for i in range(0,len(S)):
        Psum += (S[i])**2

    for i in range(0,len(S)):
        Pdiff += (D[i])**2

    return Psum*Pdiff

def IDM(S,D):
    Sum=0
    L= (len(D)+1)/2
    for j in range(0,len(D)):
        Sum += D[j]/(1+(j-L+1)**2)

    return Sum

def CON(S,D):
    Sum=0
    L= (len(D)+1)/2
    for j in range(0,len(D)):
        Sum += ((j-L+1)**2)*D[j]

    return Sum

def ENT(S,D):
    SumS=0
    SumD=0

    for i in range(0,len(S)):
        if(S[i]!=0):
            SumS += S[i]*(math.log10(S[i]))
        if(D[i]!=0):
            SumD += D[i]*(math.log10(D[i]))

    return -SumS-SumD
asm = np.array([[0 for j in range(width-m)] for i in range(height-n)],dtype=float)
idm = np.array([[0 for j in range(width-m)] for i in range(height-n)],dtype=float)
con = np.array([[0 for j in range(width-m)] for i in range(height-n)],dtype=float)
ent = np.array([[0 for j in range(width-m)] for i in range(height-n)],dtype=float)
def norm(ar):
  sum = np.sum(ar)
  normalized_data = ar / sum
  return normalized_data


for k in range(height-n):
  for l in range(width-m):
    arr1 = {i: 0 for i in range(2*pixel_range[1]+1)}
    arr2 = {i: 0 for i in range(-pixel_range[1], pixel_range[1]+1)}
    for i in range(n-d2):
      for j in range(m-d1):
        arr1[array[k+i][l+j]+array[k+i+d2][l+j+d1]] = arr1[array[k+i][l+j]+array[k+i+d2][l+j+d1]] + 1

        arr2[array[k+i][l+j]-array[k+i+d2][l+j+d1]] = arr2[array[k+i][l+j]-array[k+i+d2][l+j+d1]] + 1

        if(j==0):
          temp_sum[array[k+i][l+j]+array[k+i+d2][l+j+d1]] = temp_sum[array[k+i][l+j]+array[k+i+d2][l+j+d1]] + 1
          temp_diff[array[k+i][l+j]-array[k+i+d2][l+j+d1]] = temp_diff[array[k+i][l+j]-array[k+i+d2][l+j+d1]] + 1

    S = norm(np.array(list(arr1.values())))
    D = norm(np.array(list(arr2.values())))
    print(np.array(list(arr1.values())), S, np.array(list(arr2.values())), D)
    asm[k][l]=float(ASM(S,D))
    idm[k][l]=float(IDM(S,D))
    con[k][l]=float(CON(S,D))
    ent[k][l]=float(ENT(S,D))

asm
idm
con
ent
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
data ={}
df = pd.DataFrame(data)


# Create a 2D NumPy array
array_2d = asm

# Flatten the array
flattened_array_asm = array_2d.ravel()

# Create a Pandas Series from the flattened array
asm_s = pd.Series(flattened_array_asm)
df['asm'] = asm_s


# Create a 2D NumPy array
array_2d = idm

# Flatten the array
flattened_array_idm = array_2d.ravel()

# Create a Pandas Series from the flattened array
idm_s = pd.Series(flattened_array_idm)
df['idm'] = idm_s


# Create a 2D NumPy array
array_2d = con

# Flatten the array
flattened_array_con = array_2d.ravel()

# Create a Pandas Series from the flattened array
con_s = pd.Series(flattened_array_con)
df['con'] = con_s

# Create a 2D NumPy array
array_2d = ent

# Flatten the array
flattened_array_ent = array_2d.ravel()

# Create a Pandas Series from the flattened array
ent_s = pd.Series(flattened_array_ent)
df['ent'] = ent_s








# df= pd.read_csv("/content/drive/MyDrive/GNR 607/wine-clustering.csv")
# df
X = df.iloc[:,2]
y = df.iloc[:,1]
plt.scatter(X,y);
# # import module
# from sklearn.preprocessing import StandardScaler

# # compute required values
# scaler = StandardScaler()
# model = scaler.fit(df)
# scaled_data = model.transform(df)

# # print scaled data
# print(scaled_data)

# from sklearn.decomposition import PCA
# pca_2 = PCA(n_components=3)
# pca_2_result = pca_2.fit_transform(scaled_data)
# print('Explained variation per principal component: {}'.format(pca_2.explained_variance_ratio_))

# # >> Explained variation per principal component: [0.36198848 0.1920749 ]

# print('Cumulative variance explained by 2 principal components: {:.2%}'.format(np.sum(pca_2.explained_variance_ratio_)))

scaled_data = df

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=2,max_iter=1000)
kmeans.fit(scaled_data)
cl = kmeans.predict(scaled_data)
cl.shape
X = df.iloc[:,1]
y = df.iloc[:,-1]
plt.scatter(X,y,c=cl);
kmeans.inertia_


# from sklearn.model_selection import ParameterGrid
# import sklearn.metrics as metrics

# # candidate values for our number of cluster
# parameters = [2, 3, 4, 5, 10, 15, 20, 25, 30, 35, 40]
# # instantiating ParameterGrid, pass number of clusters as input
# parameter_grid = ParameterGrid({'n_clusters': parameters})
# best_score = -1
# kmeans_model = KMeans()     # instantiating KMeans model
# silhouette_scores = []
# # evaluation based on silhouette_score
# for p in parameter_grid:
#     kmeans_model.set_params(**p)    # set current hyper parameter
#     kmeans_model.fit(df)          # fit model on wine dataset, this will find clusters based on parameter p
#     ss = metrics.silhouette_score(df, kmeans_model.labels_)   # calculate silhouette_score
#     silhouette_scores += [ss]       # store all the scores
#     print('Parameter:', p, 'Score', ss)
#     # check p which has the best score
#     if ss > best_score:
#         best_score = ss
#         best_grid = p
# # plotting silhouette score
# plt.bar(range(len(silhouette_scores)), list(silhouette_scores), align='center', color='#722f59', width=0.5)
# plt.xticks(range(len(silhouette_scores)), list(parameters))
# plt.title('Silhouette Score', fontweight='bold')
# plt.xlabel('Number of Clusters')
# plt.show()

# fitting KMeans
kmeans = KMeans(n_clusters=2)
kmeans.fit(scaled_data)

final_cl = kmeans.predict(scaled_data)
# # def min_arr(arr):
# #   min = 255
# #   for i in arr:
# #    if min>i:
# #     min = i
# #   return min

def max_arr(arr):
    max = 0
    for i in range(0,arr.size):
      if max<arr[i]:
       max = arr[i]
    return max
# # max_v = max_arr(cl)# cl = scale_to_0_255(cl
# # final_cl = final_cl*255
max_v = max_arr(final_cl)
final_cl = final_cl*(255/max_v)
final_cl.shape
final_cl = final_cl.reshape(ent.shape[0],ent.shape[1])
final_cl.shape
final_cl
# import numpy as np

# def scale_to_0_255(arr):
#     min_value = min_arr(arr)
#     max_value = max_arr(arr)

#     scaled_arr = []

#     for value in arr:
#         scaled_value = ((value - min_value) / (max_value - min_value)) * 255
#         scaled_arr.append(scaled_value)

#     return scaled_arr

final_cl
count = 0
for i in final_cl:
  for j in i:
    count+=j

count = count/255
count
df_new = pd.DataFrame(final_cl)
df_new.to_csv('sample_data.csv', index=True)

# image = cv2.cvtColor(cl)  # Convert grayscale to BGR (color) image

# # Save the image to a file (optional)
# cv2.imwrite('output.png', image)

grayscale_image = cv2.merge((final_cl,final_cl,final_cl))


# Save the grayscale image to a file (optional)
cv2.imwrite('output.png', grayscale_image)

# image = cv2.cvtColor(cl)  # Convert grayscale to BGR (color) image

def max_arr2d(arr):
    max = 0
    for i in range(0,arr.size):
      for j in range(0,arr[0].size):
        if max<arr[i][j]:
          max = arr[i][j]

    if(max == 0):
      max = 255
    return max

# # Save the image to a file (optional)
# cv2.imwrite('output.png', image)
asm_=asm*(255/max_arr2(asm_s))
grayscale_image = cv2.merge((asm,asm,asm))

# Save the grayscale image to a file (optional)
cv2.imwrite('asm.png', grayscale_image)
arr1 = {i: 0 for i in range(2*pixel_range[1]+1)}
    arr2 = {i: 0 for i in range(-pixel_range[1], pixel_range[1]+1)}
